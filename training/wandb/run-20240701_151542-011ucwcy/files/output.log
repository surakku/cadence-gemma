
Loading the parameters from ../model/2b-it.pt into cuda:1
Parameters loaded.
GRIFFIN
18685440
projector.proj.0.weight
projector.proj.0.bias
projector.proj.2.weight
projector.proj.2.bias
projector.proj.4.weight
projector.proj.4.bias
embedder.input_embedding
blocks.0.temporal_pre_norm.scale
blocks.0.recurrent_block.linear_y.weight
blocks.0.recurrent_block.linear_y.bias
blocks.0.recurrent_block.linear_x.weight
blocks.0.recurrent_block.linear_x.bias
blocks.0.recurrent_block.linear_out.weight
blocks.0.recurrent_block.linear_out.bias
blocks.0.recurrent_block.conv_1d.w
blocks.0.recurrent_block.conv_1d.b
blocks.0.recurrent_block.rg_lru.a_param
blocks.0.recurrent_block.rg_lru.input_gate.w
blocks.0.recurrent_block.rg_lru.input_gate.b
blocks.0.recurrent_block.rg_lru.a_gate.w
blocks.0.recurrent_block.rg_lru.a_gate.b
blocks.0.channel_pre_norm.scale
blocks.0.mlp_block.ffw_up.w
blocks.0.mlp_block.ffw_up.b
blocks.0.mlp_block.ffw_down.weight
blocks.0.mlp_block.ffw_down.bias
blocks.1.temporal_pre_norm.scale
blocks.1.recurrent_block.linear_y.weight
blocks.1.recurrent_block.linear_y.bias
blocks.1.recurrent_block.linear_x.weight
blocks.1.recurrent_block.linear_x.bias
blocks.1.recurrent_block.linear_out.weight
blocks.1.recurrent_block.linear_out.bias
blocks.1.recurrent_block.conv_1d.w
blocks.1.recurrent_block.conv_1d.b
blocks.1.recurrent_block.rg_lru.a_param
blocks.1.recurrent_block.rg_lru.input_gate.w
blocks.1.recurrent_block.rg_lru.input_gate.b
blocks.1.recurrent_block.rg_lru.a_gate.w
blocks.1.recurrent_block.rg_lru.a_gate.b
blocks.1.channel_pre_norm.scale
blocks.1.mlp_block.ffw_up.w
blocks.1.mlp_block.ffw_up.b
blocks.1.mlp_block.ffw_down.weight
blocks.1.mlp_block.ffw_down.bias
blocks.2.temporal_pre_norm.scale
blocks.2.attention_block.proj_q.weight
blocks.2.attention_block.proj_k.weight
blocks.2.attention_block.proj_v.weight
blocks.2.attention_block.proj_final.weight
blocks.2.attention_block.proj_final.bias
blocks.2.channel_pre_norm.scale
blocks.2.mlp_block.ffw_up.w
blocks.2.mlp_block.ffw_up.b
blocks.2.mlp_block.ffw_down.weight
blocks.2.mlp_block.ffw_down.bias
blocks.3.temporal_pre_norm.scale
blocks.3.recurrent_block.linear_y.weight
blocks.3.recurrent_block.linear_y.bias
blocks.3.recurrent_block.linear_x.weight
blocks.3.recurrent_block.linear_x.bias
blocks.3.recurrent_block.linear_out.weight
blocks.3.recurrent_block.linear_out.bias
blocks.3.recurrent_block.conv_1d.w
blocks.3.recurrent_block.conv_1d.b
blocks.3.recurrent_block.rg_lru.a_param
blocks.3.recurrent_block.rg_lru.input_gate.w
blocks.3.recurrent_block.rg_lru.input_gate.b
blocks.3.recurrent_block.rg_lru.a_gate.w
blocks.3.recurrent_block.rg_lru.a_gate.b
blocks.3.channel_pre_norm.scale
blocks.3.mlp_block.ffw_up.w
blocks.3.mlp_block.ffw_up.b
blocks.3.mlp_block.ffw_down.weight
blocks.3.mlp_block.ffw_down.bias
blocks.4.temporal_pre_norm.scale
blocks.4.recurrent_block.linear_y.weight
blocks.4.recurrent_block.linear_y.bias
blocks.4.recurrent_block.linear_x.weight
blocks.4.recurrent_block.linear_x.bias
blocks.4.recurrent_block.linear_out.weight
blocks.4.recurrent_block.linear_out.bias
blocks.4.recurrent_block.conv_1d.w
blocks.4.recurrent_block.conv_1d.b
blocks.4.recurrent_block.rg_lru.a_param
blocks.4.recurrent_block.rg_lru.input_gate.w
blocks.4.recurrent_block.rg_lru.input_gate.b
blocks.4.recurrent_block.rg_lru.a_gate.w
blocks.4.recurrent_block.rg_lru.a_gate.b
blocks.4.channel_pre_norm.scale
blocks.4.mlp_block.ffw_up.w
blocks.4.mlp_block.ffw_up.b
blocks.4.mlp_block.ffw_down.weight
blocks.4.mlp_block.ffw_down.bias
blocks.5.temporal_pre_norm.scale
blocks.5.attention_block.proj_q.weight
blocks.5.attention_block.proj_k.weight
blocks.5.attention_block.proj_v.weight
blocks.5.attention_block.proj_final.weight
blocks.5.attention_block.proj_final.bias
blocks.5.channel_pre_norm.scale
blocks.5.mlp_block.ffw_up.w
blocks.5.mlp_block.ffw_up.b
blocks.5.mlp_block.ffw_down.weight
blocks.5.mlp_block.ffw_down.bias
blocks.6.temporal_pre_norm.scale
blocks.6.recurrent_block.linear_y.weight
blocks.6.recurrent_block.linear_y.bias
blocks.6.recurrent_block.linear_x.weight
blocks.6.recurrent_block.linear_x.bias
blocks.6.recurrent_block.linear_out.weight
blocks.6.recurrent_block.linear_out.bias
blocks.6.recurrent_block.conv_1d.w
blocks.6.recurrent_block.conv_1d.b
blocks.6.recurrent_block.rg_lru.a_param
blocks.6.recurrent_block.rg_lru.input_gate.w
blocks.6.recurrent_block.rg_lru.input_gate.b
blocks.6.recurrent_block.rg_lru.a_gate.w
blocks.6.recurrent_block.rg_lru.a_gate.b
blocks.6.channel_pre_norm.scale
blocks.6.mlp_block.ffw_up.w
blocks.6.mlp_block.ffw_up.b
blocks.6.mlp_block.ffw_down.weight
blocks.6.mlp_block.ffw_down.bias
blocks.7.temporal_pre_norm.scale
blocks.7.recurrent_block.linear_y.weight
blocks.7.recurrent_block.linear_y.bias
blocks.7.recurrent_block.linear_x.weight
blocks.7.recurrent_block.linear_x.bias
blocks.7.recurrent_block.linear_out.weight
blocks.7.recurrent_block.linear_out.bias
blocks.7.recurrent_block.conv_1d.w
blocks.7.recurrent_block.conv_1d.b
blocks.7.recurrent_block.rg_lru.a_param
blocks.7.recurrent_block.rg_lru.input_gate.w
blocks.7.recurrent_block.rg_lru.input_gate.b
blocks.7.recurrent_block.rg_lru.a_gate.w
blocks.7.recurrent_block.rg_lru.a_gate.b
blocks.7.channel_pre_norm.scale
blocks.7.mlp_block.ffw_up.w
blocks.7.mlp_block.ffw_up.b
blocks.7.mlp_block.ffw_down.weight
blocks.7.mlp_block.ffw_down.bias
blocks.8.temporal_pre_norm.scale
blocks.8.attention_block.proj_q.weight
blocks.8.attention_block.proj_k.weight
blocks.8.attention_block.proj_v.weight
blocks.8.attention_block.proj_final.weight
blocks.8.attention_block.proj_final.bias
blocks.8.channel_pre_norm.scale
blocks.8.mlp_block.ffw_up.w
blocks.8.mlp_block.ffw_up.b
blocks.8.mlp_block.ffw_down.weight
blocks.8.mlp_block.ffw_down.bias
blocks.9.temporal_pre_norm.scale
blocks.9.recurrent_block.linear_y.weight
blocks.9.recurrent_block.linear_y.bias
blocks.9.recurrent_block.linear_x.weight
blocks.9.recurrent_block.linear_x.bias
blocks.9.recurrent_block.linear_out.weight
blocks.9.recurrent_block.linear_out.bias
blocks.9.recurrent_block.conv_1d.w
blocks.9.recurrent_block.conv_1d.b
blocks.9.recurrent_block.rg_lru.a_param
blocks.9.recurrent_block.rg_lru.input_gate.w
blocks.9.recurrent_block.rg_lru.input_gate.b
blocks.9.recurrent_block.rg_lru.a_gate.w
blocks.9.recurrent_block.rg_lru.a_gate.b
blocks.9.channel_pre_norm.scale
blocks.9.mlp_block.ffw_up.w
blocks.9.mlp_block.ffw_up.b
blocks.9.mlp_block.ffw_down.weight
blocks.9.mlp_block.ffw_down.bias
blocks.10.temporal_pre_norm.scale
blocks.10.recurrent_block.linear_y.weight
blocks.10.recurrent_block.linear_y.bias
blocks.10.recurrent_block.linear_x.weight
blocks.10.recurrent_block.linear_x.bias
blocks.10.recurrent_block.linear_out.weight
blocks.10.recurrent_block.linear_out.bias
blocks.10.recurrent_block.conv_1d.w
blocks.10.recurrent_block.conv_1d.b
blocks.10.recurrent_block.rg_lru.a_param
blocks.10.recurrent_block.rg_lru.input_gate.w
blocks.10.recurrent_block.rg_lru.input_gate.b
blocks.10.recurrent_block.rg_lru.a_gate.w
blocks.10.recurrent_block.rg_lru.a_gate.b
blocks.10.channel_pre_norm.scale
blocks.10.mlp_block.ffw_up.w
blocks.10.mlp_block.ffw_up.b
blocks.10.mlp_block.ffw_down.weight
blocks.10.mlp_block.ffw_down.bias
blocks.11.temporal_pre_norm.scale
blocks.11.attention_block.proj_q.weight
blocks.11.attention_block.proj_k.weight
blocks.11.attention_block.proj_v.weight
blocks.11.attention_block.proj_final.weight
blocks.11.attention_block.proj_final.bias
blocks.11.channel_pre_norm.scale
blocks.11.mlp_block.ffw_up.w
blocks.11.mlp_block.ffw_up.b
blocks.11.mlp_block.ffw_down.weight
blocks.11.mlp_block.ffw_down.bias
blocks.12.temporal_pre_norm.scale
blocks.12.recurrent_block.linear_y.weight
blocks.12.recurrent_block.linear_y.bias
blocks.12.recurrent_block.linear_x.weight
blocks.12.recurrent_block.linear_x.bias
blocks.12.recurrent_block.linear_out.weight
blocks.12.recurrent_block.linear_out.bias
blocks.12.recurrent_block.conv_1d.w
blocks.12.recurrent_block.conv_1d.b
blocks.12.recurrent_block.rg_lru.a_param
blocks.12.recurrent_block.rg_lru.input_gate.w
blocks.12.recurrent_block.rg_lru.input_gate.b
blocks.12.recurrent_block.rg_lru.a_gate.w
blocks.12.recurrent_block.rg_lru.a_gate.b
blocks.12.channel_pre_norm.scale
blocks.12.mlp_block.ffw_up.w
blocks.12.mlp_block.ffw_up.b
blocks.12.mlp_block.ffw_down.weight
blocks.12.mlp_block.ffw_down.bias
blocks.13.temporal_pre_norm.scale
blocks.13.recurrent_block.linear_y.weight
blocks.13.recurrent_block.linear_y.bias
blocks.13.recurrent_block.linear_x.weight
blocks.13.recurrent_block.linear_x.bias
blocks.13.recurrent_block.linear_out.weight
blocks.13.recurrent_block.linear_out.bias
blocks.13.recurrent_block.conv_1d.w
blocks.13.recurrent_block.conv_1d.b
blocks.13.recurrent_block.rg_lru.a_param
blocks.13.recurrent_block.rg_lru.input_gate.w
blocks.13.recurrent_block.rg_lru.input_gate.b
blocks.13.recurrent_block.rg_lru.a_gate.w
blocks.13.recurrent_block.rg_lru.a_gate.b
blocks.13.channel_pre_norm.scale
blocks.13.mlp_block.ffw_up.w
blocks.13.mlp_block.ffw_up.b
blocks.13.mlp_block.ffw_down.weight
blocks.13.mlp_block.ffw_down.bias
blocks.14.temporal_pre_norm.scale
blocks.14.attention_block.proj_q.weight
blocks.14.attention_block.proj_k.weight
blocks.14.attention_block.proj_v.weight
blocks.14.attention_block.proj_final.weight
blocks.14.attention_block.proj_final.bias
blocks.14.channel_pre_norm.scale
blocks.14.mlp_block.ffw_up.w
blocks.14.mlp_block.ffw_up.b
blocks.14.mlp_block.ffw_down.weight
blocks.14.mlp_block.ffw_down.bias
blocks.15.temporal_pre_norm.scale
blocks.15.recurrent_block.linear_y.weight
blocks.15.recurrent_block.linear_y.bias
blocks.15.recurrent_block.linear_x.weight
blocks.15.recurrent_block.linear_x.bias
blocks.15.recurrent_block.linear_out.weight
blocks.15.recurrent_block.linear_out.bias
blocks.15.recurrent_block.conv_1d.w
blocks.15.recurrent_block.conv_1d.b
blocks.15.recurrent_block.rg_lru.a_param
blocks.15.recurrent_block.rg_lru.input_gate.w
blocks.15.recurrent_block.rg_lru.input_gate.b
blocks.15.recurrent_block.rg_lru.a_gate.w
blocks.15.recurrent_block.rg_lru.a_gate.b
blocks.15.channel_pre_norm.scale
blocks.15.mlp_block.ffw_up.w
blocks.15.mlp_block.ffw_up.b
blocks.15.mlp_block.ffw_down.weight
blocks.15.mlp_block.ffw_down.bias
blocks.16.temporal_pre_norm.scale
blocks.16.recurrent_block.linear_y.weight
blocks.16.recurrent_block.linear_y.bias
blocks.16.recurrent_block.linear_x.weight
blocks.16.recurrent_block.linear_x.bias
blocks.16.recurrent_block.linear_out.weight
blocks.16.recurrent_block.linear_out.bias
blocks.16.recurrent_block.conv_1d.w
blocks.16.recurrent_block.conv_1d.b
blocks.16.recurrent_block.rg_lru.a_param
blocks.16.recurrent_block.rg_lru.input_gate.w
blocks.16.recurrent_block.rg_lru.input_gate.b
blocks.16.recurrent_block.rg_lru.a_gate.w
blocks.16.recurrent_block.rg_lru.a_gate.b
blocks.16.channel_pre_norm.scale
blocks.16.mlp_block.ffw_up.w
blocks.16.mlp_block.ffw_up.b
blocks.16.mlp_block.ffw_down.weight
blocks.16.mlp_block.ffw_down.bias
blocks.17.temporal_pre_norm.scale
blocks.17.attention_block.proj_q.weight
blocks.17.attention_block.proj_k.weight
blocks.17.attention_block.proj_v.weight
blocks.17.attention_block.proj_final.weight
blocks.17.attention_block.proj_final.bias
blocks.17.channel_pre_norm.scale
blocks.17.mlp_block.ffw_up.w
blocks.17.mlp_block.ffw_up.b
blocks.17.mlp_block.ffw_down.weight
blocks.17.mlp_block.ffw_down.bias
blocks.18.temporal_pre_norm.scale
blocks.18.recurrent_block.linear_y.weight
blocks.18.recurrent_block.linear_y.bias
blocks.18.recurrent_block.linear_x.weight
blocks.18.recurrent_block.linear_x.bias
blocks.18.recurrent_block.linear_out.weight
blocks.18.recurrent_block.linear_out.bias
blocks.18.recurrent_block.conv_1d.w
blocks.18.recurrent_block.conv_1d.b
blocks.18.recurrent_block.rg_lru.a_param
blocks.18.recurrent_block.rg_lru.input_gate.w
blocks.18.recurrent_block.rg_lru.input_gate.b
blocks.18.recurrent_block.rg_lru.a_gate.w
blocks.18.recurrent_block.rg_lru.a_gate.b
blocks.18.channel_pre_norm.scale
blocks.18.mlp_block.ffw_up.w
blocks.18.mlp_block.ffw_up.b
blocks.18.mlp_block.ffw_down.weight
blocks.18.mlp_block.ffw_down.bias
blocks.19.temporal_pre_norm.scale
blocks.19.recurrent_block.linear_y.weight
blocks.19.recurrent_block.linear_y.bias
blocks.19.recurrent_block.linear_x.weight
blocks.19.recurrent_block.linear_x.bias
blocks.19.recurrent_block.linear_out.weight
blocks.19.recurrent_block.linear_out.bias
blocks.19.recurrent_block.conv_1d.w
blocks.19.recurrent_block.conv_1d.b
blocks.19.recurrent_block.rg_lru.a_param
blocks.19.recurrent_block.rg_lru.input_gate.w
blocks.19.recurrent_block.rg_lru.input_gate.b
blocks.19.recurrent_block.rg_lru.a_gate.w
blocks.19.recurrent_block.rg_lru.a_gate.b
blocks.19.channel_pre_norm.scale
blocks.19.mlp_block.ffw_up.w
blocks.19.mlp_block.ffw_up.b
blocks.19.mlp_block.ffw_down.weight
blocks.19.mlp_block.ffw_down.bias
blocks.20.temporal_pre_norm.scale
blocks.20.attention_block.proj_q.weight
blocks.20.attention_block.proj_k.weight
blocks.20.attention_block.proj_v.weight
blocks.20.attention_block.proj_final.weight
blocks.20.attention_block.proj_final.bias
blocks.20.channel_pre_norm.scale
blocks.20.mlp_block.ffw_up.w
blocks.20.mlp_block.ffw_up.b
blocks.20.mlp_block.ffw_down.weight
blocks.20.mlp_block.ffw_down.bias
blocks.21.temporal_pre_norm.scale
blocks.21.recurrent_block.linear_y.weight
blocks.21.recurrent_block.linear_y.bias
blocks.21.recurrent_block.linear_x.weight
blocks.21.recurrent_block.linear_x.bias
blocks.21.recurrent_block.linear_out.weight
blocks.21.recurrent_block.linear_out.bias
blocks.21.recurrent_block.conv_1d.w
blocks.21.recurrent_block.conv_1d.b
blocks.21.recurrent_block.rg_lru.a_param
blocks.21.recurrent_block.rg_lru.input_gate.w
blocks.21.recurrent_block.rg_lru.input_gate.b
blocks.21.recurrent_block.rg_lru.a_gate.w
blocks.21.recurrent_block.rg_lru.a_gate.b
blocks.21.channel_pre_norm.scale
blocks.21.mlp_block.ffw_up.w
blocks.21.mlp_block.ffw_up.b
blocks.21.mlp_block.ffw_down.weight
blocks.21.mlp_block.ffw_down.bias
blocks.22.temporal_pre_norm.scale
blocks.22.recurrent_block.linear_y.weight
blocks.22.recurrent_block.linear_y.bias
blocks.22.recurrent_block.linear_x.weight
blocks.22.recurrent_block.linear_x.bias
blocks.22.recurrent_block.linear_out.weight
blocks.22.recurrent_block.linear_out.bias
blocks.22.recurrent_block.conv_1d.w
blocks.22.recurrent_block.conv_1d.b
blocks.22.recurrent_block.rg_lru.a_param
blocks.22.recurrent_block.rg_lru.input_gate.w
blocks.22.recurrent_block.rg_lru.input_gate.b
blocks.22.recurrent_block.rg_lru.a_gate.w
blocks.22.recurrent_block.rg_lru.a_gate.b
blocks.22.channel_pre_norm.scale
blocks.22.mlp_block.ffw_up.w
blocks.22.mlp_block.ffw_up.b
blocks.22.mlp_block.ffw_down.weight
blocks.22.mlp_block.ffw_down.bias
blocks.23.temporal_pre_norm.scale
blocks.23.attention_block.proj_q.weight
blocks.23.attention_block.proj_k.weight
blocks.23.attention_block.proj_v.weight
blocks.23.attention_block.proj_final.weight
blocks.23.attention_block.proj_final.bias
blocks.23.channel_pre_norm.scale
blocks.23.mlp_block.ffw_up.w
blocks.23.mlp_block.ffw_up.b
blocks.23.mlp_block.ffw_down.weight
blocks.23.mlp_block.ffw_down.bias
blocks.24.temporal_pre_norm.scale
blocks.24.recurrent_block.linear_y.weight
blocks.24.recurrent_block.linear_y.bias
blocks.24.recurrent_block.linear_x.weight
blocks.24.recurrent_block.linear_x.bias
blocks.24.recurrent_block.linear_out.weight
blocks.24.recurrent_block.linear_out.bias
blocks.24.recurrent_block.conv_1d.w
blocks.24.recurrent_block.conv_1d.b
blocks.24.recurrent_block.rg_lru.a_param
blocks.24.recurrent_block.rg_lru.input_gate.w
blocks.24.recurrent_block.rg_lru.input_gate.b
blocks.24.recurrent_block.rg_lru.a_gate.w
blocks.24.recurrent_block.rg_lru.a_gate.b
blocks.24.channel_pre_norm.scale
blocks.24.mlp_block.ffw_up.w
blocks.24.mlp_block.ffw_up.b
blocks.24.mlp_block.ffw_down.weight
blocks.24.mlp_block.ffw_down.bias
blocks.25.temporal_pre_norm.scale
blocks.25.recurrent_block.linear_y.weight
blocks.25.recurrent_block.linear_y.bias
blocks.25.recurrent_block.linear_x.weight
blocks.25.recurrent_block.linear_x.bias
blocks.25.recurrent_block.linear_out.weight
blocks.25.recurrent_block.linear_out.bias
blocks.25.recurrent_block.conv_1d.w
blocks.25.recurrent_block.conv_1d.b
blocks.25.recurrent_block.rg_lru.a_param
blocks.25.recurrent_block.rg_lru.input_gate.w
blocks.25.recurrent_block.rg_lru.input_gate.b
blocks.25.recurrent_block.rg_lru.a_gate.w
blocks.25.recurrent_block.rg_lru.a_gate.b
blocks.25.channel_pre_norm.scale
blocks.25.mlp_block.ffw_up.w
blocks.25.mlp_block.ffw_up.b
blocks.25.mlp_block.ffw_down.weight
blocks.25.mlp_block.ffw_down.bias
final_norm.scale
3
/homes/jkobza/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Traceback (most recent call last):
  File "/nfs/lambda_stor_01/homes/jkobza/projects/recurrentgemma_experiments/training/train.py", line 546, in <module>
    trained_params = train_loop(
                     ^^^^^^^^^^^
  File "/nfs/lambda_stor_01/homes/jkobza/projects/recurrentgemma_experiments/training/train.py", line 258, in train_loop
    train_loss = train_step(
                 ^^^^^^^^^^^
  File "/nfs/lambda_stor_01/homes/jkobza/projects/recurrentgemma_experiments/training/train.py", line 158, in train_step
    if(n_steps % 4 == 0):
       ^^^^^^^
NameError: name 'n_steps' is not defined
Start, validation loss: -0.015061511658132076